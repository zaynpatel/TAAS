{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7c925c98",
   "metadata": {},
   "source": [
    "Tracking third deliverable:\n",
    "\n",
    "Goals: Have a completed notebook by **April 27** and a completed presentation \"5 things about matrix calculus in 15 minutes\" by **May 1.**\n",
    "\n",
    "TODO:\n",
    "\n",
    "- Linear transformations as matrices section (Motivate d's as lin ops)\n",
    "    - Ask Sarah questions during Tuesday class (ask to speak first) to complete the mapping from different m, n. \n",
    "    - Include the key fact that when we think about linear transformations as matrices we have a key reason for why matmul isn't communitive **and** this also relates to why we can't take derivatives of A^2 as 2A. (Maybe show an example that this only works unless commute like I or something else?)\n",
    "\n",
    "- Briefly discuss how the intuition for linear transformations as matrices motivates derivatives as linear operators (show a single-variable calculus example)\n",
    "    - Begin with a table of the functions you will review: scalar-valued functions (take in a vector and return a scalar), vector-valued functions (take in a vector and return a vector), scalar-valued functions with matrices as input. \n",
    "    - At this point mention `f'(x)[dx]` where we will be thinking about arbitrary infinitesimal changes in dx as a vector.\n",
    "    - Thinking about this as a vector transitions into scalar-valued functions. Show the gradient (we know we want a scalar output, we know [dx] is a column vector so what can we multiply dx by to get a scalar? The basic linear algebra answer is: \"a row vector\" but *what* are the components of this row vector? Since we know f' is a linear operator that takes in a vector we take the derivative of this vector which in multivariable calculus language means we take the component-wise derivatives of each component in the vector. That's how we know this is grad f since this linear operator treatment literally gives us the gradient. \n",
    "    - **Next is showing example 10 from the project notes** and this is a big slide because it changes our perspective of derivatives from component-wise things to *matrices.* Note to the audience that this grad f isn't a rule for *all* matrices, right? We are just thinking about how to get intuition for what grad f is in an example. \n",
    "    - In vector-valued functions we apply the same intuition of f' as a linear operator. Now we want vectors out so we can think about our components (n in, m out) so we need a matrix that's m x n. We learned that this is the Jacobian (computes partial derivatives in each direction). \n",
    "\n",
    "- Product rule and chain rule for functions on \"arbitrary vector spaces\"\n",
    "    - **Question for Sarah:** How do I understand the product rule and the chain rule (I understand it from the linear operator perspective (another chance to show the class linear transformations as matrices) but I do not understand it from the defn of the derivative. \n",
    "    - (Thursday question: f(A) = A^3. Why derivative)\n",
    "\n",
    "- Jacobian vs. Kronecker product (I think this is where we use the notebook and Julia)\n",
    "    - In this section I am most interested in showing that the Jacobian is ugly when we compute component-wise derivatives. It's easy to make Julia do it for both symbolic and numerical examples *but* we would like to \"write the Jacobian without explicitly writing it\" -- Alan Edelman. \n",
    "    - This motivates the Kronecker product A ⊗ B. Interesting, personally, because this is an operation where all 4 input/output pairs can be different numbers *and* we are doing this as the product of two matrices. Most of our typical LinAlg content was dimension specific because we were defining matrix-vector or matrix-matrix operations and needed these to be the same. \n",
    "    - Need to show the Kronecker identity (Prop 27) to the class so they know how we get the equivalence (I think this is a key thing to understand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "344241b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Julia packages\n",
    "using LinearAlgebra, Symbolics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d665647e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$$ \\begin{equation}\n",
       "\\left[\n",
       "\\begin{array}{cc}\n",
       "a & b \\\\\n",
       "c & d \\\\\n",
       "\\end{array}\n",
       "\\right]\n",
       "\\end{equation}\n",
       " $$"
      ],
      "text/plain": [
       "2×2 Matrix{Num}:\n",
       " a  b\n",
       " c  d"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define variables\n",
    "@variables a, b, c, d\n",
    "\n",
    "X = [a b; c d]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aa55822a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$$ \\begin{equation}\n",
       "\\left[\n",
       "\\begin{array}{cc}\n",
       "a^{2} + b c & a b + b d \\\\\n",
       "a c + c d & b c + d^{2} \\\\\n",
       "\\end{array}\n",
       "\\right]\n",
       "\\end{equation}\n",
       " $$"
      ],
      "text/plain": [
       "2×2 Matrix{Num}:\n",
       " a^2 + b*c  a*b + b*d\n",
       " a*c + c*d  b*c + d^2"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X^2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "18b76f17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "jac (generic function with 1 method)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This defines the function and our \"Y\" is X^2?\n",
    "\n",
    "jac(Y, X) = Symbolics.jacobian(vec(Y), vec(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f60a2f10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$$ \\begin{equation}\n",
       "\\left[\n",
       "\\begin{array}{cccc}\n",
       "2 a & b & c & 0 \\\\\n",
       "c & a + d & 0 & c \\\\\n",
       "b & 0 & a + d & b \\\\\n",
       "0 & b & c & 2 d \\\\\n",
       "\\end{array}\n",
       "\\right]\n",
       "\\end{equation}\n",
       " $$"
      ],
      "text/plain": [
       "4×4 Matrix{Num}:\n",
       " 2a      b      c   0\n",
       "  c  a + d      0   c\n",
       "  b      0  a + d   b\n",
       "  0      b      c  2d"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# I think we would get the same answer if we took the Jacobian by hand. Right, the partial derivatives...\n",
    "# ... of each term in X^2 are in the first row. 1,1 entry of X^2 is the first row of J\n",
    "# ... and 2,1 entry of X^2 is the second row of J, etc. \n",
    "\n",
    "J = jac(X^2, X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "84316a36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$$ \\begin{equation}\n",
       "\\left[\n",
       "\\begin{array}{cccc}\n",
       "2 a & b & c & 0 \\\\\n",
       "c & a + d & 0 & c \\\\\n",
       "b & 0 & a + d & b \\\\\n",
       "0 & b & c & 2 d \\\\\n",
       "\\end{array}\n",
       "\\right]\n",
       "\\end{equation}\n",
       " $$"
      ],
      "text/plain": [
       "4×4 Matrix{Num}:\n",
       " 2a      b      c   0\n",
       "  c  a + d      0   c\n",
       "  b      0  a + d   b\n",
       "  0      b      c  2d"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "begin \n",
    "    I2 = [1 0; 0 1]\n",
    "    kron(I2,X) + kron(X', I2)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5914264d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$$ \\begin{equation}\n",
       "\\left[\n",
       "\\begin{array}{cccc}\n",
       "a & b & 0 & 0 \\\\\n",
       "c & d & 0 & 0 \\\\\n",
       "0 & 0 & a & b \\\\\n",
       "0 & 0 & c & d \\\\\n",
       "\\end{array}\n",
       "\\right]\n",
       "\\end{equation}\n",
       " $$"
      ],
      "text/plain": [
       "4×4 Matrix{Num}:\n",
       " a  b  0  0\n",
       " c  d  0  0\n",
       " 0  0  a  b\n",
       " 0  0  c  d"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Symbolic representation\n",
    "SymB = [a b; c d]\n",
    "\n",
    "kron(I2, SymB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b6dd2b29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2×2 Matrix{Float64}:\n",
       " 0.251488  0.68133\n",
       " 0.814871  0.655163"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B = rand(2, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "af35f37a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4×4 Matrix{Float64}:\n",
       " 0.251488  0.68133   0.0       0.0\n",
       " 0.814871  0.655163  0.0       0.0\n",
       " 0.0       0.0       0.251488  0.68133\n",
       " 0.0       0.0       0.814871  0.655163"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kron(I2, B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "153ade9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$$ \\begin{equation}\n",
       "\\left[\n",
       "\\begin{array}{c}\n",
       "a \\mathtt{c1} + b \\mathtt{c3} \\\\\n",
       "a \\mathtt{c2} + b \\mathtt{c4} \\\\\n",
       "c \\mathtt{c1} + \\mathtt{c3} d \\\\\n",
       "c \\mathtt{c2} + \\mathtt{c4} d \\\\\n",
       "\\end{array}\n",
       "\\right]\n",
       "\\end{equation}\n",
       " $$"
      ],
      "text/plain": [
       "4-element Vector{Num}:\n",
       " a*c1 + b*c3\n",
       " a*c2 + b*c4\n",
       " c*c1 + c3*d\n",
       " c*c2 + c4*d"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A kron I\n",
    "@variables c1 , c2, c3, c4\n",
    "\n",
    "A = [a b; c d]\n",
    "C = [c1; c2; c3; c4]\n",
    "vC = vec(C)\n",
    "kron(A, I2) * vC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c83d2cb6",
   "metadata": {},
   "source": [
    "### Linear transformations as matrices\n",
    "\n",
    "> The goal of this section is to show students how to think about linear transformations as matrices and build up to a more abstract concept of **linear operators** which we will use in the matrix calculus section below.\n",
    "\n",
    "Thoughts on what to include:\n",
    "\n",
    "- Discuss the difference between [linear transformation and linear operator](https://math.stackexchange.com/questions/487933/what-is-the-difference-between-linear-transformation-and-linear-operator) in the context the audience will hear it in for matrix calculus. Define both of these (this will transition into the arbitrary linear map content)\n",
    "\n",
    "- Show some very basic examples of an arbitrary linear map you defined from R^2 -> R^2\n",
    "    - **Ask Sarah: If we think about linear transformations as matrices then isn't it also intuitive to think about them as functions?** So it is fine to use function notation at the beginning?\n",
    "\n",
    "- Then, give examples of transformations like rotations or projections (e.g. my linear approx talk)\n",
    "\n",
    "- Share the intuition behind advanced examples of linear transformations (moving from different spaces. We have transformations for R^n -> R^m so show the more general/abstract way to think about this then give some examples of R^4 -> R^2 and **what condition may make this linear** and from R^3 -> R^5, etc. What other general things can we say about linearity between two different vector spaces of different dimensions? What can we say about linearity between two vector spaces of the same dimension?\n",
    "    - I think this may be as simple as verifying the conditions of our transformation work between R^n -> R^m for different m and n. **Confirm.**\n",
    "\n",
    "- Why does this motivate linear transformations as matrices?  \n",
    "\n",
    "- How does this relate to matrix calculus?\n",
    "\n",
    "\n",
    "#### Definition of a linear transformation and brief example in numpy\n",
    "\n",
    "The word *transformation* in linear transformation comes because we are taking a vector (or matrix) as input to our function (which is defined by a matrix) and transforming it from one vector space to another vector space. In some cases we can transform the object from the same vector space to the same vector space. [Rotation matrices](https://academicflight.com/articles/kinematics/rotation-formalisms/rotation-matrix/) are an example of this type of linear transformation. Another word for this specific transformation where we transform an object from one vector space to the same vector space is an endomorphism. \n",
    "\n",
    "Anyway, the word *[linear](https://en.wikipedia.org/wiki/Linearity)* in mean our transformation satisfies two properties:\n",
    "\n",
    "- Additivity: f(x + y) = f(x) + f(y)\n",
    "- Scalar multiplication: f($\\alpha$x) = $\\alpha$f(x) $\\forall$ $\\alpha$\n",
    "\n",
    "It is not a coincidence that these two criteria for a linear transformation are also two of the most important criteria to have a vector space. \n",
    "\n",
    "Now, if we look at an example of this transformation, I define a function f to be the following matrix:\n",
    "\n",
    "f = $\\begin{bmatrix}\n",
    "1 & 2 \\\\\n",
    "7 & 3\n",
    "\\end{bmatrix}$\n",
    "\n",
    "And I define two column vectors, x and y, to be:\n",
    "\n",
    "x = $\\begin{pmatrix} 1 \\\\ 4 \\end{pmatrix}$\n",
    "y = $\\begin{pmatrix} 2 \\\\ 5 \\end{pmatrix}$\n",
    "\n",
    "Then additivity tells me that doing f(x + y) = f(x) + f(y). We can confirm this is linear in numpy. See the first and second code block below.\n",
    "\n",
    "**Notation in python: @ is the same thing as typing np.matmul(), * will be the element-wise product for vectors, + is the element-wise addition for vectors.**\n",
    "\n",
    "#### Step back: What do the entries of a matrix actually tell us?\n",
    "\n",
    "In our matrix f the column vectors of this matrix are *basis vectors* of our space. If we refer to the [standard basis](https://mathworld.wolfram.com/StandardBasis.html) then this matrix f moves the standard basis vectors by [1, 7] and [2, 3] respectively. The transformation part comes in again because we can imagine entries of x and y, these 2x1 column vectors, as *any* two real numbers. And multiplying x or y by f gives us the "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2d4b7848",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LHS: [[21]\n",
      " [48]]\n",
      "RHS: [[21]\n",
      " [48]]\n"
     ]
    }
   ],
   "source": [
    "# Check additivity\n",
    "\n",
    "f = np.array([[1, 2],\n",
    "             [7, 3]])\n",
    "\n",
    "x = np.array([[1], [4]])\n",
    "\n",
    "y = np.array([[2], [5]])\n",
    "\n",
    "# LHS of linearity\n",
    "LHS = f @ (x + y)\n",
    "print(f\"LHS: {LHS}\")\n",
    "\n",
    "# RHS of linearity\n",
    "RHS = (f @ x) + (f @ y)\n",
    "print(f\"RHS: {RHS}\")\n",
    "\n",
    "#assert LHS.all() == RHS.all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "130a118e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LHS: [[18]\n",
      " [38]]\n",
      "RHS: [[18]\n",
      " [38]]\n"
     ]
    }
   ],
   "source": [
    "# Check scalar multiplication (also called homogeniety of degree?)\n",
    "\n",
    "#alpha = 4\n",
    "\n",
    "# We can see the same thing for an arbitrary alpha value (just to show you there's nothing special about 4)\n",
    "alpha = np.random.randint(0, 10)\n",
    "\n",
    "LHS = f @ (alpha * x)\n",
    "RHS = alpha * (f @ x)\n",
    "\n",
    "print(f\"LHS: {LHS}\")\n",
    "print(f\"RHS: {RHS}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3d3a599f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$$ \\begin{equation}\n",
       "\\left[\n",
       "\\begin{array}{cc}\n",
       "a & b \\\\\n",
       "c & d \\\\\n",
       "\\end{array}\n",
       "\\right]\n",
       "\\end{equation}\n",
       " $$"
      ],
      "text/plain": [
       "2×2 Matrix{Num}:\n",
       " a  b\n",
       " c  d"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define a symbolic array\n",
    "\n",
    "@variables a b c d\n",
    "A = [a b \n",
    "    c d]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "65868bbc",
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "UndefVarError: `variables` not defined in `Main`\nSuggestion: check for spelling errors or missing imports.",
     "output_type": "error",
     "traceback": [
      "UndefVarError: `variables` not defined in `Main`\nSuggestion: check for spelling errors or missing imports.",
      ""
     ]
    }
   ],
   "source": [
    "A * tr()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ec31ab5",
   "metadata": {},
   "source": [
    "### Show the matrix dot product is equal to tr(A^T* B)\n",
    "\n",
    "\n",
    "This confirms our intuition about the element-wise multiplication equaling the tr(A^T) * B.\n",
    "\n",
    "*Would be nice to explain more about the trace operator and some of the properties like cyclic property.* What is my hypothesis on why the trace operator appears so often. \n",
    "\n",
    "Look at this [link](https://math.stackexchange.com/questions/4453933/why-is-the-trace-of-a-matrix-important)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b5a8ce6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 9, 32],\n",
       "       [ 8, 15]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = np.array([[3, 4],\n",
    "             [4, 5]])\n",
    "\n",
    "B = np.array([[3, 8],\n",
    "             [2, 3]])\n",
    "\n",
    "\n",
    "element_wise = A * B\n",
    "element_wise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5fc13abd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sums = 0\n",
    "for element in np.nditer(element_wise):\n",
    "    sums += element\n",
    "sums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "51f040cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AT = np.transpose(A)\n",
    "ATB = np.matmul(AT, B)\n",
    "\n",
    "\n",
    "traceAB = np.trace(ATB)\n",
    "traceAB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9f4b11a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 51, 156],\n",
       "       [ 32,  18]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dA = np.array([[3, 6],\n",
    "              [2, 1]])\n",
    "\n",
    "# m x n (2 x 2)\n",
    "x = np.array([[3, 4],\n",
    "             [4, 2]])\n",
    "\n",
    "# n x m (2x2)\n",
    "y = np.array([[3, 2],\n",
    "             [2, 5]])\n",
    "\n",
    "y_t = np.transpose(y)\n",
    "\n",
    "(x @ y_t) * dA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ae42b0a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 95, 144],\n",
       "       [100, 162]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Check this\n",
    "\n",
    "\n",
    "x_t = np.transpose(x)\n",
    "\n",
    "df = x_t @ dA @ y\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4da366f9",
   "metadata": {},
   "source": [
    "Weighted dot product with I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "68731731",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[17, 26],\n",
       "       [16, 18]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "I = np.identity(2)\n",
    "\n",
    "x_t @ y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f00d9eed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[17., 26.],\n",
       "       [16., 18.]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Yes, this weighting with I gives us the same answer\n",
    "\n",
    "x_t @ I @ y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a3293d3",
   "metadata": {},
   "source": [
    "### Explain the Jacobian matrix and determinant"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7730cbdd",
   "metadata": {},
   "source": [
    "### Explain the Kronecker product and give an example with Jacobian\n",
    "\n",
    "- Explain the indices notation versus Kronecker product and the interestingness of the matrix operation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "850785b3",
   "metadata": {},
   "source": [
    "### Explain chain rule for matrix calculus"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.11.5",
   "language": "julia",
   "name": "julia-1.11"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
